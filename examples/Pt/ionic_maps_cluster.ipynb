{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks and Tests of Maps for Single-Element Cluster Substrates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fontsize = plt.rcParams['font.size']\n",
    "publication_fontsize_large = 20\n",
    "publication = True\n",
    "if publication: plt.rcParams.update({'font.size': publication_fontsize_large})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt Nanocluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the ASE.Atoms instance using the fcc111 build function. The atom at the center of the cell on the top face is index number 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.cluster.cubic import FaceCenteredCubic\n",
    "surfaces = [(1, 0, 0), (1, 1, 0), (1, 1, 1)]\n",
    "layers = [5, 8, 5]\n",
    "lc = 3.94000\n",
    "PtCluster = FaceCenteredCubic('Pt', surfaces, layers, latticeconstant=lc)\n",
    "PtCluster.cell = 30 * np.eye(3)\n",
    "PtCluster.positions += [15, 15, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "view(PtCluster, viewer='x3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save the cluster coordinates to a file\n",
    "# PtCluster.write('PtCluster.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `ASE.Cell` and the generated `ASE.Atoms`, create a `MapSy.Grid` and a `MapSy.System`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapsy.data import Grid\n",
    "grid: Grid = Grid(cell=PtCluster.cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapsy.data import System\n",
    "system: System = System(grid, PtCluster, dimension=0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapsy.io.parser import ContactSpaceGenerator, ContactSpaceModel\n",
    "contactspacesettings = ContactSpaceModel.parse_obj({\"mode\": \"ionic\", \"cutoff\": 40, \"alpha\": 1.2, \"spread\" : 0.8, \"threshold\": 0.5})\n",
    "contactspace = ContactSpaceGenerator(contactspacesettings).generate(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contactspace.data['probability'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contactspace.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contactspace.nregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contactspace.boundary.gradient.modulus.plotprojections([15,15,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapsy.symfunc.input import SymmetryFunctionsModel, SymFuncModel\n",
    "from mapsy.symfunc.parser import SymmetryFunctionsParser\n",
    "symfuncsettings = SymmetryFunctionsModel.parse_obj({\"functions\": [SymFuncModel.parse_obj({\"type\":\"ac\",\"radius\":4.5,\"order\":10,\"compositional\":False,\"structural\":True}),SymFuncModel.parse_obj({\"type\":\"ac\",\"radius\":4.5,\"order\":10,\"compositional\":False,\"structural\":True,\"radial\":False})]})\n",
    "symmetryfunctions = SymmetryFunctionsParser(symfuncsettings).parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapsy.maps import Maps\n",
    "maps = Maps(system,symmetryfunctions,contactspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = maps.atcontactspace()\n",
    "#data.to_csv('maps.csv')\n",
    "# To save time, we load the data from a file\n",
    "maps.data = pd.read_csv('maps.csv', index_col=0)\n",
    "maps.features = maps.data.columns.drop(['x','y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize features to check how they look using `Maps.plot(feature: str)` or `Maps.plot(index: int)`. NOTE: to get the top face of the slab, we need to select `region=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = maps.scatter(index=0, cmap='Spectral', set_aspect='scaled')\n",
    "axes.set_xlabel('x (Å)')\n",
    "axes.set_ylabel('y (Å)')\n",
    "axes.set_title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization and post-processing purposes, perform dimensionality reduction on the generated features. Three components are useful for 2D and 3D plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1, ax2 = maps.reduce(scale=True)\n",
    "if (publication) : \n",
    "    ax1.set_title('PCA')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 5\n",
    "maps.reduce(npca, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually inspect how the PCAs correlate with the Cartesian coordinates of the points (e.g., PC0 still distinguishing between atop positions, while PC1 correlated with the distance from the defect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, gs = maps.scatter_pca_grid(index=0,cmap='Spectral',set_aspect='equal',s=70, alpha=0.05)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify how the contact space is transformed (folded) in the symmetry function space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4*1))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_title(\"\")\n",
    "x1m = maps.data['pca0'].values.astype(np.float64)\n",
    "x2m = maps.data['pca1'].values.astype(np.float64)\n",
    "fm = maps.data[maps.features[0]].values.astype(np.float64)\n",
    "fmin = np.min(fm)\n",
    "fmax = np.max(fm)\n",
    "scatter = ax.scatter(x1m,x2m,c=fm,vmin=fmin,vmax=fmax,cmap='Spectral',alpha=0.2,s=60,edgecolors='black')\n",
    "ax.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Clustering on Generated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SpectralClustering to find N clusters in the featured data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import scipy.spatial.distance as distance\n",
    "from itertools import combinations\n",
    "\n",
    "def cluster(self, nclusters=None, features=None, maxclusters=20, ntries = 1, random_state=None, scale=False):\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\"\n",
    "    # Select the features for clustering\n",
    "    if features is None:\n",
    "        self.cluster_features = self.features\n",
    "    else:\n",
    "        self.cluster_features = features\n",
    "    X = self.data[self.cluster_features].values.astype(np.float64)\n",
    "    if scale : \n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    if nclusters is not None:\n",
    "        if random_state is None:\n",
    "            # If we performed a screening, use the best random state\n",
    "            if self.best_clusters is not None:\n",
    "                if nclusters in self.best_clusters['nclusters'].values:\n",
    "                    self.random_state = self.best_clusters[self.best_clusters['nclusters']==nclusters]['random_state'].values[0]\n",
    "                    print(f'Use best random state = {self.random_state} from screening')\n",
    "                else:\n",
    "                    self.random_state = np.random.randint(0,1000)\n",
    "                    print(f'Use new random state = {self.random_state}')\n",
    "            # Otherwise, pick a random number\n",
    "            else:\n",
    "                self.random_state = np.random.randint(0,1000)\n",
    "                print(f'Use new random state = {self.random_state}')\n",
    "        else:\n",
    "            self.random_state = random_state\n",
    "            print(f'Use given random state = {self.random_state}')\n",
    "#        labels = SpectralClustering(n_clusters = nclusters, random_state=self.random_state).fit_predict(X)\n",
    "        labels = GaussianMixture(n_components=nclusters).fit_predict(X)\n",
    "        self.data['Cluster'] = labels\n",
    "        # Store number of clusters\n",
    "        self.nclusters = nclusters\n",
    "        # Compute the cluster centers in features space\n",
    "        self.cluster_centers = self.data.groupby('Cluster')[self.cluster_features].mean().values.astype(np.float64)\n",
    "        # Compute the number of points in each cluster\n",
    "        self.cluster_sizes = self.data.groupby('Cluster').size().values\n",
    "        # Generate clusters connectivity matrix\n",
    "        self.cluster_graph = self.graph(self.data['Cluster'])\n",
    "        self.cluster_edges = self.cluster_graph.copy()\n",
    "        for i in range(nclusters):\n",
    "            self.cluster_edges[i,i] = 0\n",
    "    else:\n",
    "        cluster_range = range(2, maxclusters)\n",
    "        cluster_random_states = []\n",
    "        cluster_sizes = []\n",
    "        silhouette_scores = []\n",
    "        db_indexes = []\n",
    "        # Loop over different numbers of clusters\n",
    "        for nclusters in cluster_range:\n",
    "            random_states = np.random.randint(0,1000,ntries)\n",
    "            for random_state in random_states:\n",
    "                cluster_random_states.append(random_state)\n",
    "#                labels = SpectralClustering(n_clusters=nclusters, random_state=random_state).fit_predict(X)\n",
    "                labels = GaussianMixture(n_components=nclusters, random_state=random_state).fit_predict(X)\n",
    "                actual_nclusters = len(np.unique(labels))\n",
    "                cluster_sizes.append(actual_nclusters)\n",
    "                score = silhouette_score(X, labels)\n",
    "                silhouette_scores.append(score)\n",
    "                index = davies_bouldin_score(X, labels)\n",
    "                db_indexes.append(index)\n",
    "        # Store all clusters data\n",
    "        self.cluster_screening = pd.DataFrame({'nclusters': cluster_sizes, 'random_state': cluster_random_states, 'silhouette_score': silhouette_scores, 'db_index': db_indexes})\n",
    "        # Find the best clusters according to Silhouette Score\n",
    "        best_db = self.cluster_screening.loc[self.cluster_screening.groupby('nclusters')['db_index'].idxmin()]\n",
    "        best_sil = self.cluster_screening.loc[self.cluster_screening.groupby('nclusters')['silhouette_score'].idxmax()]\n",
    "        self.best_clusters = best_db \n",
    "        # Plot Silhouette Scores\n",
    "        fig, ax1 = plt.subplots()\n",
    "        # Plot Silhouette Scores on the left y-axis\n",
    "        ax1.scatter(cluster_sizes, silhouette_scores, color='b', marker='o', label='Silhouette Score')\n",
    "        ax1.plot(best_db['nclusters'],best_db['silhouette_score'], '-', color='b')\n",
    "        ax1.plot(best_sil['nclusters'],best_sil['silhouette_score'], ':', color='b')\n",
    "        ax1.set_xlabel('Number of Clusters')\n",
    "        ax1.set_ylabel('Silhouette Score', color='b')\n",
    "        ax1.tick_params(axis='y', labelcolor='b')\n",
    "        # Create a second y-axis to the right for Davies-Bouldin Index\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.scatter(cluster_sizes, db_indexes, color='r', marker='s', label='Davies-Bouldin Index')\n",
    "        ax2.plot(best_db['nclusters'],best_db['db_index'], '-', color='r')\n",
    "        ax2.plot(best_sil['nclusters'],best_sil['db_index'], ':', color='r')\n",
    "        ax2.set_ylabel('Davies-Bouldin Index', color='r')\n",
    "        ax2.tick_params(axis='y', labelcolor='r')\n",
    "        # Title and grid\n",
    "        ax1.set_title('Silhouette Score and Davies-Bouldin Index vs. Number of Clusters')\n",
    "        ax1.grid(True)\n",
    "        return fig, ax1, ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntries = 1\n",
    "if publication: ntries = 3\n",
    "fig, ax1, ax2 = cluster(maps,maxclusters=30, ntries=ntries)\n",
    "if publication: \n",
    "    ax1.set_title('')\n",
    "    ax2.set_title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster(maps,nclusters=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the clusters, plot the connectivity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(maps.cluster_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the clusters and the connectivity, find the high-symmetry sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.sites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = maps.data.loc[maps.centroids,['x','y','z']].values\n",
    "for i in range(pos.shape[0]):\n",
    "    print(\"O \"+\" \".join(str(x) for x in pos[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(self, feature = None, index = None, axes=['x','y'], region=0, categorical=False, centroids=False, splitby=None, splitby_index=None, set_aspect='on', **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Filter data by region\n",
    "    filterdata = self.data[self.contactspace.data['region'] == region]\n",
    "    # Check that contact space maps have been generated\n",
    "    if self.data is None:\n",
    "        raise RuntimeError(\"No contact space data available.\")\n",
    "    # Check if feature or index is provided and if it is valid\n",
    "    if feature is not None:\n",
    "        if feature not in self.data.columns:\n",
    "            raise ValueError(f\"Feature {feature} not found in maps data.\")\n",
    "    elif index is not None:\n",
    "        if index >= len(self.features) or index < 0:\n",
    "            raise ValueError(f\"Index {index} out of bounds.\")\n",
    "        feature = self.features[index]\n",
    "        print(f\"Plotting feature {self.features[index]}\")\n",
    "    else:\n",
    "        f = None # No feature provided\n",
    "    for axis in axes:\n",
    "        if axis not in self.data.columns:\n",
    "            raise ValueError(f\"Axis {axis} not found in maps data.\")\n",
    "    if set_aspect not in ['on','off','equal','scaled']:\n",
    "        raise ValueError(f\"set_aspect must be one of ['on','off','equal','scaled']\")\n",
    "    # Select the axes for the plot\n",
    "    x1 = filterdata[axes[0]].values.astype(np.float64)\n",
    "    x2 = filterdata[axes[1]].values.astype(np.float64)\n",
    "    # Select the axis to plot\n",
    "    f = filterdata[feature].values.astype(np.float64)\n",
    "    # Select the axis for splitting\n",
    "    if splitby is not None:\n",
    "        if splitby not in self.data.columns:\n",
    "            raise ValueError(f\"Split axis {splitby[0]} not found in maps data.\")\n",
    "        s = filterdata[splitby].values\n",
    "        if splitby_index is not None:\n",
    "            if splitby_index >= len(np.unique(s)) or splitby_index < 0:\n",
    "                raise ValueError(f\"Split index {splitby_index} out of bounds.\")\n",
    "            nsplit = 1\n",
    "            fig, axs = plt.subplots(nsplit, 1, figsize=(8, 4*nsplit))\n",
    "            axslist = [axs]\n",
    "        else:\n",
    "            nsplit = np.unique(s).size\n",
    "            fig, axs = plt.subplots(nsplit, 1, figsize=(8, 4*nsplit))\n",
    "            axslist = axs.flat\n",
    "    else:\n",
    "        nsplit = 1\n",
    "        fig, axs = plt.subplots(nsplit, 1, figsize=(8, 4*nsplit))\n",
    "        axslist = [axs]\n",
    "    if categorical : \n",
    "        nf = np.unique(f).size\n",
    "        colors = [ c for c in map(plt.cm.tab20, range(nf))]\n",
    "    else:\n",
    "        fmin = np.min(f)\n",
    "        fmax = np.max(f)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    # Plot the data    \n",
    "    # Generate 2D plots for each unique value of the split variable\n",
    "    for i,ax in enumerate(axslist):\n",
    "        if splitby is not None:\n",
    "            if splitby_index is not None:\n",
    "                sval = np.unique(s)[splitby_index]\n",
    "            else:\n",
    "                sval = np.unique(s)[i]\n",
    "            ax.set_title(f\"Map of {feature} for {splitby} = {sval:6.2f}\")\n",
    "            mask = filterdata[splitby]==sval\n",
    "            x1m = x1[mask]\n",
    "            x2m = x2[mask]\n",
    "            fm = f[mask]\n",
    "        else:\n",
    "            ax.set_title(f\"Map of {feature}\")\n",
    "            x1m = x1\n",
    "            x2m = x2\n",
    "            fm = f\n",
    "        ax.set_xlabel(f\"{axes[0]}\")\n",
    "        ax.set_ylabel(f\"{axes[1]}\")\n",
    "        if not categorical:\n",
    "            if f is None:\n",
    "                scatter = ax.scatter(x1m,x2m,**kwargs)\n",
    "            else:\n",
    "                scatter = ax.scatter(x1m,x2m,c=fm,vmin=fmin,vmax=fmax,**kwargs)\n",
    "        else:\n",
    "            for i,fvalue in enumerate(np.unique(f)):\n",
    "                scatter = ax.scatter(x1m[fm==fvalue],x2m[fm==fvalue],color=colors[i],label=f'{feature} = {i:2}',**kwargs)\n",
    "        if centroids: \n",
    "            if self.centroids is None:\n",
    "                raise RuntimeError(\"No centroids available.\")\n",
    "            pos = self.data.loc[self.centroids,axes].values\n",
    "            if splitby is not None:\n",
    "                posmask = self.data.loc[self.centroids,splitby].values == sval\n",
    "            else:\n",
    "                posmask = np.ones(pos.shape[0],dtype=bool)\n",
    "            ax.scatter(pos[posmask,0],pos[posmask,1],c='black',marker='x',label='Centroids',**kwargs)\n",
    "        if categorical:\n",
    "            leg = ax.legend(bbox_to_anchor=(1.01, 0.5), loc=\"center left\")\n",
    "            for lh in leg.legend_handles: \n",
    "                lh.set_alpha(1)\n",
    "        ax.axis(set_aspect)\n",
    "    if not categorical and f is not None:\n",
    "        if nsplit > 1 :\n",
    "            colorbar = fig.colorbar( scatter, ax=axs.ravel().tolist())\n",
    "        else:\n",
    "            colorbar = fig.colorbar( scatter, ax=ax)\n",
    "        colorbar.solids.set_alpha(1.0)    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = scatter(maps,feature='Cluster', categorical=True, alpha=0.8, s=20, splitby='z', splitby_index=2, set_aspect='scaled', centroids=True)\n",
    "ax.set_xlabel('x (Å)')\n",
    "ax.set_ylabel('y (Å)')\n",
    "ax.set_title('Clusters')\n",
    "if publication:\n",
    "    ax.set_title('')\n",
    "    ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = scatter(maps,feature='Cluster', categorical=True, alpha=0.1, s=10, set_aspect='scaled', centroids=False)\n",
    "ax.set_xlabel('x (Å)')\n",
    "ax.set_ylabel('y (Å)')\n",
    "ax.set_title('Clusters')\n",
    "if publication:\n",
    "    ax.set_title('')\n",
    "    ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = ['pca0','pca1']\n",
    "fig, ax = maps.scatter(feature='Cluster', categorical=True, axes=axes, alpha=0.2, s=70, edgecolors='black', set_aspect='on')\n",
    "G = nx.from_numpy_array(maps.cluster_edges,create_using=nx.DiGraph,parallel_edges=False)\n",
    "pos = maps.data.loc[maps.centroids,axes].values\n",
    "weights = [ d['weight']/4000 for (u, v, d) in G.edges(data=True)]\n",
    "nx.draw(G, pos, node_size=maps.cluster_sizes/50, width=weights, ax=ax, alpha=0.8, edgecolors='black')\n",
    "limits=ax.axis('on') # turns on axis\n",
    "ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_title('Clusters')\n",
    "if publication:\n",
    "    ax.set_title('')\n",
    "    ax.get_legend().remove()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
